{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading entire TIFF (3D)...\n"
     ]
    }
   ],
   "source": [
    "# Ran this on the selfnet data and then put it in the test script\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import exposure\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from skimage.filters import median\n",
    "import stackview\n",
    "\n",
    "# ===============================\n",
    "# INPUT FILE PATH\n",
    "# ===============================\n",
    "image_path = r\"C:\\Users\\rexsw\\Desktop\\JHU\\BDD\\Dendrite_2p_20250925\\New data2\\raw\\F13_2_20250323_roi1_Red_shifted.tif\"\n",
    "assert os.path.exists(image_path), f\"File not found: {image_path}\"\n",
    "\n",
    "print(\">>> Loading entire TIFF (3D)...\")\n",
    "image = imread(image_path)  # Expect shape (Z, Y, X)\n",
    "\n",
    "assert image.ndim == 3, f\"Expected 3D TIFF. Got shape: {image.shape}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0fb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackview.slice(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66e82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Global normalization...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # ===============================\n",
    "# # GLOBAL NORMALIZATION\n",
    "# # ===============================\n",
    "print(\">>> Global normalization...\")\n",
    "vmin = np.percentile(image, 0.5)\n",
    "vmax = np.percentile(image, 99.5)\n",
    "image_norm = np.clip((image - vmin) / (vmax - vmin), 0, 1)\n",
    "\n",
    "# Convert to 12-bit range for processing stability\n",
    "image_uint = (image_norm * 1024).astype(np.uint16)\n",
    "\n",
    "i1 = image_uint\n",
    "i2 = image_uint\n",
    "i3 = image_uint\n",
    "i4 = image_uint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2849d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackview.histogram(image_uint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53dee2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Applying global CLAHE...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# GLOBAL CLAHE (gentle)\n",
    "# ===============================\n",
    "print(\">>> Applying global CLAHE...\")\n",
    "image_clahe = exposure.equalize_adapthist(\n",
    "    image_uint, \n",
    "    clip_limit=0.005 #0.005  # â†“ keep noise controlled\n",
    ")\n",
    "\n",
    "i1_clahe = exposure.equalize_adapthist(\n",
    "    i1, \n",
    "    clip_limit=0.05 #0.005  # â†“ keep noise controlled\n",
    ")\n",
    "\n",
    "i2_clahe = exposure.equalize_adapthist(\n",
    "    i2, \n",
    "    clip_limit=0.5 #0.005  # â†“ keep noise controlled\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cba6559e7fa409e963b12f4fb5fe292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=1â€¦"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.histogram(image_clahe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60034d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bccc10b3b6421ca96b69daf039eae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=1â€¦"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stackview.histogram(i1_clahe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cf24128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0b4e9f56b246c4a4c30d3ddd65f96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=1â€¦"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stackview.histogram(i2_clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9d1b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Wavelet denoise (BayesShrink, soft)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# WAVELET DENOISING\n",
    "# ===============================\n",
    "print(\">>> Wavelet denoise (BayesShrink, soft)...\")\n",
    "denoised = denoise_wavelet(\n",
    "    image_clahe,\n",
    "    channel_axis=None,\n",
    "    method='BayesShrink',\n",
    "    mode='soft',\n",
    "    wavelet='db2',\n",
    "    rescale_sigma=True\n",
    ")\n",
    "\n",
    "i1_dn1 = denoise_wavelet(\n",
    "    i1_clahe,\n",
    "    channel_axis=None,\n",
    "    method='BayesShrink',\n",
    "    mode='soft',\n",
    "    wavelet='db2',\n",
    "    rescale_sigma=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63052ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackview.histogram(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c403854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Median filtering per slice...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# MEDIAN SMOOTHING\n",
    "# ===============================\n",
    "print(\">>> Median filtering per slice...\")\n",
    "denoised = (denoised * 1024).astype(np.uint16)\n",
    "filtered = np.array([\n",
    "    median(denoised[z], footprint=np.ones((3,3)))  # 3x3 smoothing\n",
    "    for z in range(denoised.shape[0])\n",
    "])\n",
    "\n",
    "i1_dn2 = np.array([\n",
    "    median(i1_clahe[z], footprint=np.ones((3,3)))  # 3x3 smoothing\n",
    "    for z in range(i1_clahe.shape[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71c24be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Adaptive percentile stretch...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# ROBUST PERCENTILE CONTRAST STRETCH\n",
    "# (less aggressive â†’ preserves faint signals)\n",
    "# ===============================\n",
    "print(\">>> Adaptive percentile stretch...\")\n",
    "low = np.percentile(filtered, 78)     # tuneable\n",
    "high = np.percentile(filtered, 99.9)  # tuneable\n",
    "\n",
    "final = np.clip((filtered - low) / (high - low), 0, 1)\n",
    "final = (final * 4095).astype(np.uint16)  # convert to 12-bit TIFF depth\n",
    "I = final\n",
    "\n",
    "low1 = np.percentile(i1_dn1, 78)     # tuneable\n",
    "high1 = np.percentile(i1_dn1, 99.9)  # tuneable\n",
    "\n",
    "final1 = np.clip((i1_dn1 - low1) / (high1 - low1), 0, 1)\n",
    "final1 = (final1 * 4095).astype(np.uint16)  # convert to 12-bit TIFF depth\n",
    "I1 = final1\n",
    "\n",
    "low12 = np.percentile(i1_dn2, 78)     # tuneable\n",
    "high12 = np.percentile(i1_dn2, 99.9)  # tuneable\n",
    "\n",
    "final12 = np.clip((i1_dn2 - low12) / (high12 - low12), 0, 1)\n",
    "final12 = (final12 * 4095).astype(np.uint16)  # convert to 12-bit TIFF depth\n",
    "I12 = final12\n",
    "\n",
    "low3 = np.percentile(i3, 78)     # tuneable\n",
    "high3 = np.percentile(i3, 99.9)  # tuneable\n",
    "\n",
    "final3 = np.clip((i3 - low3) / (high3 - low3), 0, 1)\n",
    "final3 = (final3 * 4095).astype(np.uint16)  # convert to 12-bit TIFF depth\n",
    "I3 = final3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9dc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackview.histogram(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f43ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# SAVE RESULTS\n",
    "# ===============================\n",
    "# save_dir = r\"C:\\Users\\rexsw\\Desktop\\JHU\\BDD\\SpineDetect-joey-branch\\processed\"\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# save_path = os.path.join(save_dir, \"F13_2_20250323_roi1_Red_shifted_contrast_clahe_wavelet_med.tif\")\n",
    "# imsave(save_path, filtered)\n",
    "# print(f\"âœ… Saved processed image: {save_path}\")\n",
    "\n",
    "# ===============================\n",
    "# QUICK VISUAL CHECK (middle slice)\n",
    "# ===============================\n",
    "# mid = final.shape[0] // 2\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.title(\"Final Processed (Middle Slice)\")\n",
    "# plt.imshow(final[mid], cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "print(\"ðŸŽ‰ Preprocessing completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "934fbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046b27e5f5934df197d82be7c90e3133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=1024, width=1024â€¦"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "stackview.curtain(I3, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6,4))\n",
    "# plt.hist(image_clahe.ravel(), bins=256, color='gray', alpha=0.8)\n",
    "# plt.title(\"Intensity Histogram\")\n",
    "# plt.xlabel(\"Pixel Intensity\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
