{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61261a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install napari tifffile trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f431de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TIFF stack...\n",
      "Original volume shape: (60, 1024, 1024)\n",
      "Downsampled shape: (30, 512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/ms6k8rtn2s5cxz9b6gypxgd40000gn/T/ipykernel_61026/3862403074.py:26: FutureWarning: `napari.view_image` is deprecated and will be removed in napari 0.7.0.\n",
      "Use `viewer = napari.Viewer(); viewer.add_image(...)` instead.\n",
      "  viewer = napari.view_image(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Viewer opened: rotate with right mouse, zoom with scroll\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "3D Visualization of Neuron Z-Stack Using Napari\n",
    "-----------------------------------------------\n",
    "• Loads z-stack TIFF (Z, Y, X)\n",
    "• Optional downsampling to reduce memory usage\n",
    "• Opens interactive 3D viewer\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import napari\n",
    "\n",
    "# ✅ User settings\n",
    "tiff_path = \"/Users/joeyroberts/Desktop/Spines/Processed/processed_3D.tif\"   # Update if needed\n",
    "downsample_z = 2          # Reduce slices by factor\n",
    "downsample_xy = 2         # Reduce resolution by factor\n",
    "\n",
    "print(\"Loading TIFF stack...\")\n",
    "volume = imread(tiff_path)  # Shape: (Z, Y, X)\n",
    "print(\"Original volume shape:\", volume.shape)\n",
    "\n",
    "volume_ds = volume[::downsample_z, ::downsample_xy, ::downsample_xy]\n",
    "print(\"Downsampled shape:\", volume_ds.shape)\n",
    "\n",
    "# ✅ View in 3D\n",
    "viewer = napari.view_image(\n",
    "    volume_ds,\n",
    "    name=\"Neuron Z-Stack\",\n",
    "    rendering=\"attenuated_mip\",  # good for neuron imaging\n",
    "    contrast_limits=[np.min(volume_ds), np.max(volume_ds)]\n",
    ")\n",
    "\n",
    "viewer.dims.ndisplay = 3  # Force 3D mode\n",
    "\n",
    "print(\"✅ Viewer opened: rotate with right mouse, zoom with scroll\")\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a62552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading volume...\n",
      "Original shape: (625, 1024, 1024)\n",
      "Downsampled shape: (313, 512, 512)\n",
      "Effective pixel sizes (um): Z=2.000, Y=0.192, X=0.192\n",
      "Initial params: {'sigma_xy': 1.2, 'sigma_z': 0.4, 'spine_min_dist': 4, 'min_prominence': 0.06, 'dbscan_eps_um': 0.35, 'dbscan_min_samples': 1}\n",
      "\n",
      "--- Attempt 1 with params: {'sigma_xy': 1.2, 'sigma_z': 0.4, 'spine_min_dist': 4, 'min_prominence': 0.06, 'dbscan_eps_um': 0.35, 'dbscan_min_samples': 1}\n",
      "Denoising with gaussian (sigma_z=0.80, sigma_xy=1.20)...\n",
      "Applying Frangi (scale_range 1 -> 1.20)...\n",
      "Binary dendrite voxels: 198317\n",
      "Skeletonizing (for grouping)...\n",
      "Feature score max: 0.9999999999982547 mean: 0.0002873278590336595\n",
      "Primary raw peak candidates: 672\n",
      "Secondary nearby candidates: 974\n",
      "All combined candidates: 974\n",
      "After DBSCAN keep: 974\n",
      "Clusters merged -> 974\n",
      "After grouping by skeleton: 933\n",
      "After size/intensity filtering: 933\n",
      "Detection succeeded on attempt 1\n",
      "Saving outputs...\n",
      "Saved to /Users/joeyroberts/Desktop/Spines/Detected\n",
      "Launching Napari...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tifffile import imread, imsave\n",
    "from skimage.filters import frangi, threshold_otsu\n",
    "from skimage.morphology import skeletonize_3d, binary_dilation, remove_small_objects, binary_closing\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import cKDTree\n",
    "import napari\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =====================================================\n",
    "# USER SETTINGS — (Adjust these first if needed)\n",
    "# =====================================================\n",
    "tiff_path = \"/Users/joeyroberts/Desktop/Spines/Processed/processed_3D.tif\"\n",
    "\n",
    "px_xy = 0.096  # microns per pixel (XY)\n",
    "px_z = 1.0     # microns per slice (Z)\n",
    "\n",
    "# Expected physical spine sizes (for filtering)\n",
    "MIN_SPINE_DIAM_UM = 0.25\n",
    "MAX_SPINE_DIAM_UM = 1.2\n",
    "\n",
    "# Detection scales (start conservative)\n",
    "sigma_xy = 1.2       # smoothing / Frangi upper scale (in XY voxels)\n",
    "sigma_z = 0.4        # smoothing Z scale (in voxels)\n",
    "spine_min_dist = 4   # minimum voxel distance between peaks (initial)\n",
    "min_prominence = 0.06  # initial feature threshold (0-1)\n",
    "\n",
    "# SECONDARY pass: lower threshold to recover faint heads near shaft\n",
    "SECONDARY_MIN_PROM = 0.02\n",
    "SECONDARY_MIN_DIST = 2\n",
    "\n",
    "downsample = (2, 2, 2)  # Z,Y,X downsample factors to speed up\n",
    "\n",
    "# DBSCAN settings (will be relaxed if no detections)\n",
    "dbscan_eps_um = 0.35  # in microns\n",
    "dbscan_min_samples = 1\n",
    "\n",
    "# clustering to merge detections per-skeleton\n",
    "NEIGHBOR_DIST_UM = 0.25  # how close along skeleton two detections count as same (um)\n",
    "\n",
    "# misc\n",
    "save_dir = \"/Users/joeyroberts/Desktop/Spines/Detected\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Utility helpers\n",
    "# =====================================================\n",
    "def relax_params(params):\n",
    "    \"\"\"Slightly relax parameters (called when no candidates).\"\"\"\n",
    "    params['min_prominence'] = max(0.005, params['min_prominence'] * 0.6)\n",
    "    params['spine_min_dist'] = max(1, int(params['spine_min_dist'] * 0.8))\n",
    "    params['dbscan_eps_um'] = min(1.0, params['dbscan_eps_um'] * 1.3)\n",
    "    return params\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# LOAD + DOWNSAMPLE\n",
    "# =====================================================\n",
    "print(\"Loading volume...\")\n",
    "vol = imread(tiff_path).astype(np.float32)\n",
    "print(\"Original shape:\", vol.shape)\n",
    "\n",
    "z_ds, y_ds, x_ds = downsample\n",
    "if tuple(downsample) != (1,1,1):\n",
    "    vol = vol[::z_ds, ::y_ds, ::x_ds]\n",
    "    print(\"Downsampled shape:\", vol.shape)\n",
    "\n",
    "Z, Y, X = vol.shape\n",
    "\n",
    "# update effective pixel sizes after downsample\n",
    "eff_px_z = px_z * z_ds\n",
    "eff_px_y = px_xy * y_ds\n",
    "eff_px_x = px_xy * x_ds\n",
    "\n",
    "# =====================================================\n",
    "# INITIAL PARAMS (we keep them in a dict to relax if needed)\n",
    "# =====================================================\n",
    "params = {\n",
    "    'sigma_xy': sigma_xy,\n",
    "    'sigma_z': sigma_z,\n",
    "    'spine_min_dist': spine_min_dist,\n",
    "    'min_prominence': min_prominence,\n",
    "    'dbscan_eps_um': dbscan_eps_um,\n",
    "    'dbscan_min_samples': dbscan_min_samples,\n",
    "}\n",
    "\n",
    "print(\"Effective pixel sizes (um): Z=%.3f, Y=%.3f, X=%.3f\" % (eff_px_z, eff_px_y, eff_px_x))\n",
    "print(\"Initial params:\", params)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# MAIN PROCESSING (with automatic relaxation loop)\n",
    "# =====================================================\n",
    "MAX_TRIES = 4\n",
    "final_coords = None\n",
    "\n",
    "for attempt in range(MAX_TRIES):\n",
    "    print(\"\\n--- Attempt\", attempt+1, \"with params:\", params)\n",
    "\n",
    "    # 1) Denoise (fast Gaussian)\n",
    "    print(\"Denoising with gaussian (sigma_z=%.2f, sigma_xy=%.2f)...\" % (params['sigma_z']*2, params['sigma_xy']))\n",
    "    den = gaussian_filter(vol, sigma=(params['sigma_z']*2, params['sigma_xy'], params['sigma_xy']))\n",
    "    den = (den - den.min()) / (den.max() - den.min() + 1e-12)\n",
    "\n",
    "    # 2) Frangi enhancement (tubular structure)\n",
    "    print(\"Applying Frangi (scale_range 1 -> %.2f)...\" % max(1.0, params['sigma_xy']))\n",
    "    try:\n",
    "        vessel = frangi(den, scale_range=(1, max(1.0, params['sigma_xy'])),\n",
    "                        scale_step=1, alpha=0.7, beta=0.5, gamma=15, black_ridges=False)\n",
    "    except TypeError:\n",
    "        vessel = frangi(den)\n",
    "    vessel = (vessel - vessel.min()) / (vessel.max() - vessel.min() + 1e-12)\n",
    "\n",
    "    # 3) Dendrite mask\n",
    "    try:\n",
    "        th = threshold_otsu(vessel)\n",
    "    except Exception:\n",
    "        th = np.percentile(vessel, 50)\n",
    "    binary = vessel > (th * 1.05)  # slightly less aggressive to keep thin shafts\n",
    "    binary = remove_small_objects(binary, min_size=150)\n",
    "    binary = binary_closing(binary, footprint=np.ones((1,3,3)))\n",
    "    binary = binary_dilation(binary, footprint=np.ones((1,3,3)))\n",
    "\n",
    "    print(\"Binary dendrite voxels:\", int(binary.sum()))\n",
    "\n",
    "    # 4) Skeletonize dendrite for grouping\n",
    "    print(\"Skeletonizing (for grouping)...\")\n",
    "    sk = skeletonize_3d(binary).astype(np.uint8)\n",
    "    sk_coords = np.argwhere(sk > 0)\n",
    "    if sk_coords.size == 0:\n",
    "        print(\"Warning: skeleton empty — relaxing and retrying.\")\n",
    "        params = relax_params(params)\n",
    "        continue\n",
    "    sk_tree = cKDTree(sk_coords * np.array([eff_px_z, eff_px_y, eff_px_x]))\n",
    "\n",
    "    # 5) Feature score (curvature * proximity to dendrite * intensity)\n",
    "    curv = gaussian_filter(vessel, sigma=(params['sigma_z'], params['sigma_xy']*0.7, params['sigma_xy']*0.7))\n",
    "    dist = distance_transform_edt(~binary)\n",
    "    local_int = den\n",
    "    feat = curv * (1.0 / (1.0 + dist)) * (local_int ** 1.0)\n",
    "    feat = (feat - feat.min()) / (feat.max() - feat.min() + 1e-12)\n",
    "\n",
    "    # zero out low-intensity areas\n",
    "    low_mask = den < np.percentile(den, 55)\n",
    "    feat[low_mask] = 0.0\n",
    "\n",
    "    print(\"Feature score max:\", float(feat.max()), \"mean:\", float(feat.mean()))\n",
    "\n",
    "    # 6) Primary local maxima detection (conservative)\n",
    "    coords = peak_local_max(\n",
    "        feat,\n",
    "        min_distance=max(1, params['spine_min_dist']),\n",
    "        threshold_abs=params['min_prominence'],\n",
    "        footprint=np.ones((3, 5, 5))\n",
    "    )\n",
    "    print(\"Primary raw peak candidates:\", len(coords))\n",
    "\n",
    "    # 7) Secondary pass: lower-threshold peaks near dendrite to recover faint heads\n",
    "    coords_secondary = peak_local_max(\n",
    "        feat,\n",
    "        min_distance=max(1, SECONDARY_MIN_DIST),\n",
    "        threshold_abs=SECONDARY_MIN_PROM,\n",
    "        footprint=np.ones((3, 5, 5))\n",
    "    )\n",
    "    # keep secondary only if they are within some micron distance to dendrite (dist < 2 um)\n",
    "    if len(coords_secondary) > 0:\n",
    "        coords_sec_near = []\n",
    "        for c in coords_secondary:\n",
    "            zc,yc,xc = c\n",
    "            if dist[zc,yc,xc] * eff_px_y <= 2.0:  # use approx physical distance (um)\n",
    "                coords_sec_near.append(c)\n",
    "        coords_sec_near = np.array(coords_sec_near, dtype=int) if len(coords_sec_near) else np.zeros((0,3),int)\n",
    "    else:\n",
    "        coords_sec_near = np.zeros((0,3),int)\n",
    "    print(\"Secondary nearby candidates:\", len(coords_sec_near))\n",
    "\n",
    "    # Merge primary + secondary unique coords\n",
    "    if coords.size == 0:\n",
    "        all_coords = coords_sec_near\n",
    "    elif coords_sec_near.size == 0:\n",
    "        all_coords = coords\n",
    "    else:\n",
    "        # stack and unique by integer positions\n",
    "        all_coords = np.vstack((coords, coords_sec_near))\n",
    "        all_coords = np.unique(all_coords, axis=0)\n",
    "    print(\"All combined candidates:\", len(all_coords))\n",
    "\n",
    "    if len(all_coords) == 0:\n",
    "        print(\"No combined candidates — relaxing and retrying...\")\n",
    "        params = relax_params(params)\n",
    "        continue\n",
    "\n",
    "    # 8) DBSCAN clustering on um-scaled coords to merge tiny jittered peaks\n",
    "    uv = all_coords.astype(float)\n",
    "    uv[:,0] *= eff_px_z; uv[:,1] *= eff_px_y; uv[:,2] *= eff_px_x\n",
    "    clustering = DBSCAN(eps=params['dbscan_eps_um'], min_samples=params['dbscan_min_samples']).fit(uv)\n",
    "    labels = clustering.labels_\n",
    "    keep_mask = labels != -1\n",
    "    coords_kept = all_coords[keep_mask]\n",
    "    labels_kept = labels[keep_mask]\n",
    "    print(\"After DBSCAN keep:\", len(coords_kept))\n",
    "\n",
    "    if len(coords_kept) == 0:\n",
    "        print(\"All removed by DBSCAN — relaxing and retrying...\")\n",
    "        params = relax_params(params)\n",
    "        continue\n",
    "\n",
    "    # 9) Merge DBSCAN clusters into centroids, but then group **by nearest skeleton voxel**\n",
    "    merged = []\n",
    "    for lab in np.unique(labels_kept):\n",
    "        pts = coords_kept[labels_kept == lab]\n",
    "        # choose the highest-feature point in the cluster\n",
    "        best_idx = None\n",
    "        best_val = -np.inf\n",
    "        for p in pts:\n",
    "            v = feat[tuple(p)]\n",
    "            if v > best_val:\n",
    "                best_val = v\n",
    "                best_idx = p\n",
    "        merged.append(best_idx)\n",
    "    merged = np.array(merged).astype(int)\n",
    "    print(\"Clusters merged ->\", len(merged))\n",
    "\n",
    "    # build mapping: each merged point -> nearest skeleton index\n",
    "    if merged.size == 0:\n",
    "        print(\"Merged empty — relaxing and retrying...\")\n",
    "        params = relax_params(params)\n",
    "        continue\n",
    "\n",
    "    merged_float = merged.astype(float)\n",
    "    merged_um = merged_float.copy()\n",
    "    merged_um[:,0] *= eff_px_z; merged_um[:,1] *= eff_px_y; merged_um[:,2] *= eff_px_x\n",
    "    dists, idxs = sk_tree.query(merged_um, k=1)\n",
    "    # now group merged points by skeleton index and keep the single best per skeleton neighborhood\n",
    "    sk_group = {}\n",
    "    for i, sk_idx in enumerate(idxs):\n",
    "        sk_group.setdefault(int(sk_idx), []).append(merged[i])\n",
    "\n",
    "    final_by_skel = []\n",
    "    for sk_idx, pts in sk_group.items():\n",
    "        # if multiple merged pts map to same sk voxel, keep the one with larger feat value\n",
    "        best = None; best_val = -np.inf\n",
    "        for p in pts:\n",
    "            val = feat[tuple(p)]\n",
    "            if val > best_val:\n",
    "                best_val = val; best = p\n",
    "        final_by_skel.append(best)\n",
    "    final_by_skel = np.array(final_by_skel).astype(int)\n",
    "    print(\"After grouping by skeleton:\", len(final_by_skel))\n",
    "\n",
    "    # 10) Size & intensity filter around each final candidate\n",
    "    min_vox_area = np.pi * ((MIN_SPINE_DIAM_UM / 2.0) / eff_px_y) ** 2\n",
    "    max_vox_area = np.pi * ((MAX_SPINE_DIAM_UM / 2.0) / eff_px_y) ** 2\n",
    "    final = []\n",
    "    for (z,y,x) in final_by_skel:\n",
    "        z0 = max(0, z-2); z1 = min(Z, z+3)\n",
    "        y0 = max(0, y-3); y1 = min(Y, y+4)\n",
    "        x0 = max(0, x-3); x1 = min(X, x+4)\n",
    "        window = den[z0:z1, y0:y1, x0:x1]\n",
    "        local_thr = np.percentile(window, 60)\n",
    "        area_count = (window > local_thr).sum()\n",
    "        # accept if area within plausible range (allow some leeway)\n",
    "        if area_count >= max(1, min_vox_area * 0.5) and area_count <= max_vox_area * 8:\n",
    "            final.append((z,y,x))\n",
    "    final = np.array(final)\n",
    "    print(\"After size/intensity filtering:\", len(final))\n",
    "\n",
    "    if final.size == 0:\n",
    "        print(\"No final candidates after filtering — relaxing and retrying...\")\n",
    "        params = relax_params(params)\n",
    "        continue\n",
    "\n",
    "    # success\n",
    "    final_coords = final\n",
    "    print(\"Detection succeeded on attempt\", attempt+1)\n",
    "    break\n",
    "\n",
    "# end loop\n",
    "\n",
    "if final_coords is None or len(final_coords) == 0:\n",
    "    print(\"WARNING: No spines detected after all relaxation attempts. Try manual parameter tuning or provide a crop for tuning.\")\n",
    "    final_coords = np.zeros((0,3), dtype=int)\n",
    "\n",
    "# =====================================================\n",
    "# SAVE OUTPUTS\n",
    "# =====================================================\n",
    "print(\"Saving outputs...\")\n",
    "imsave(os.path.join(save_dir, \"vessel_3D.tif\"), (vessel * 255).astype(np.uint8))\n",
    "\n",
    "spine_mask = np.zeros_like(vol, dtype=np.uint8)\n",
    "for (z,y,x) in final_coords:\n",
    "    spine_mask[int(z), int(y), int(x)] = 255\n",
    "imsave(os.path.join(save_dir, \"spine_candidates_pruned.tif\"), spine_mask)\n",
    "print(\"Saved to\", save_dir)\n",
    "\n",
    "# =====================================================\n",
    "# VISUALIZATION\n",
    "# =====================================================\n",
    "print(\"Launching Napari...\")\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(den, name=\"Denoised\")\n",
    "viewer.add_image(vessel, name=\"Dendrite Vesselness\", opacity=0.45)\n",
    "viewer.add_image((binary.astype(np.uint8) * 255), name=\"DendriteMask\", opacity=0.25)\n",
    "if len(final_coords) > 0:\n",
    "    viewer.add_points(final_coords, name=\"Spine Detections\", size=4, face_color='yellow')\n",
    "viewer.dims.ndisplay = 3\n",
    "napari.run()\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544ef5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
